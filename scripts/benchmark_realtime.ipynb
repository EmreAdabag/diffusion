{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea/diffusion1/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Imports**\n",
    "# diffusion policy import\n",
    "from typing import Tuple, Sequence\n",
    "import numpy as np\n",
    "import torch\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# env import\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import pymunk\n",
    "import pymunk.pygame_util\n",
    "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
    "from pymunk.vec2d import Vec2d\n",
    "import shapely.geometry as sg\n",
    "import cv2\n",
    "import skimage.transform as st\n",
    "from skvideo.io import vwrite\n",
    "from IPython.display import Video\n",
    "import time\n",
    "\n",
    "from imm.state_nn import RoboIMM as ImmState\n",
    "from imm.vision_nn import RoboIMM as ImmVision\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### **Environment**\n",
    "#@markdown Defines a PyMunk-based Push-T environment `PushTEnv`.\n",
    "#@markdown\n",
    "#@markdown **Goal**: push the gray T-block into the green area.\n",
    "#@markdown\n",
    "#@markdown Adapted from [Implicit Behavior Cloning](https://implicitbc.github.io/)\n",
    "\n",
    "\n",
    "positive_y_is_up: bool = False\n",
    "\"\"\"Make increasing values of y point upwards.\n",
    "\n",
    "When True::\n",
    "\n",
    "    y\n",
    "    ^\n",
    "    |      . (3, 3)\n",
    "    |\n",
    "    |   . (2, 2)\n",
    "    |\n",
    "    +------ > x\n",
    "\n",
    "When False::\n",
    "\n",
    "    +------ > x\n",
    "    |\n",
    "    |   . (2, 2)\n",
    "    |\n",
    "    |      . (3, 3)\n",
    "    v\n",
    "    y\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def to_pygame(p: Tuple[float, float], surface: pygame.Surface) -> Tuple[int, int]:\n",
    "    \"\"\"Convenience method to convert pymunk coordinates to pygame surface\n",
    "    local coordinates.\n",
    "\n",
    "    Note that in case positive_y_is_up is False, this function wont actually do\n",
    "    anything except converting the point to integers.\n",
    "    \"\"\"\n",
    "    if positive_y_is_up:\n",
    "        return round(p[0]), surface.get_height() - round(p[1])\n",
    "    else:\n",
    "        return round(p[0]), round(p[1])\n",
    "\n",
    "\n",
    "def light_color(color: SpaceDebugColor):\n",
    "    color = np.minimum(1.2 * np.float32([color.r, color.g, color.b, color.a]), np.float32([255]))\n",
    "    color = SpaceDebugColor(r=color[0], g=color[1], b=color[2], a=color[3])\n",
    "    return color\n",
    "\n",
    "class DrawOptions(pymunk.SpaceDebugDrawOptions):\n",
    "    def __init__(self, surface: pygame.Surface) -> None:\n",
    "        \"\"\"Draw a pymunk.Space on a pygame.Surface object.\n",
    "\n",
    "        Typical usage::\n",
    "\n",
    "        >>> import pymunk\n",
    "        >>> surface = pygame.Surface((10,10))\n",
    "        >>> space = pymunk.Space()\n",
    "        >>> options = pymunk.pygame_util.DrawOptions(surface)\n",
    "        >>> space.debug_draw(options)\n",
    "\n",
    "        You can control the color of a shape by setting shape.color to the color\n",
    "        you want it drawn in::\n",
    "\n",
    "        >>> c = pymunk.Circle(None, 10)\n",
    "        >>> c.color = pygame.Color(\"pink\")\n",
    "\n",
    "        See pygame_util.demo.py for a full example\n",
    "\n",
    "        Since pygame uses a coordiante system where y points down (in contrast\n",
    "        to many other cases), you either have to make the physics simulation\n",
    "        with Pymunk also behave in that way, or flip everything when you draw.\n",
    "\n",
    "        The easiest is probably to just make the simulation behave the same\n",
    "        way as Pygame does. In that way all coordinates used are in the same\n",
    "        orientation and easy to reason about::\n",
    "\n",
    "        >>> space = pymunk.Space()\n",
    "        >>> space.gravity = (0, -1000)\n",
    "        >>> body = pymunk.Body()\n",
    "        >>> body.position = (0, 0) # will be positioned in the top left corner\n",
    "        >>> space.debug_draw(options)\n",
    "\n",
    "        To flip the drawing its possible to set the module property\n",
    "        :py:data:`positive_y_is_up` to True. Then the pygame drawing will flip\n",
    "        the simulation upside down before drawing::\n",
    "\n",
    "        >>> positive_y_is_up = True\n",
    "        >>> body = pymunk.Body()\n",
    "        >>> body.position = (0, 0)\n",
    "        >>> # Body will be position in bottom left corner\n",
    "\n",
    "        :Parameters:\n",
    "                surface : pygame.Surface\n",
    "                    Surface that the objects will be drawn on\n",
    "        \"\"\"\n",
    "        self.surface = surface\n",
    "        super(DrawOptions, self).__init__()\n",
    "\n",
    "    def draw_circle(\n",
    "        self,\n",
    "        pos: Vec2d,\n",
    "        angle: float,\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        p = to_pygame(pos, self.surface)\n",
    "\n",
    "        pygame.draw.circle(self.surface, fill_color.as_int(), p, round(radius), 0)\n",
    "        pygame.draw.circle(self.surface, light_color(fill_color).as_int(), p, round(radius-4), 0)\n",
    "\n",
    "        circle_edge = pos + Vec2d(radius, 0).rotated(angle)\n",
    "        p2 = to_pygame(circle_edge, self.surface)\n",
    "        line_r = 2 if radius > 20 else 1\n",
    "        # pygame.draw.lines(self.surface, outline_color.as_int(), False, [p, p2], line_r)\n",
    "\n",
    "    def draw_segment(self, a: Vec2d, b: Vec2d, color: SpaceDebugColor) -> None:\n",
    "        p1 = to_pygame(a, self.surface)\n",
    "        p2 = to_pygame(b, self.surface)\n",
    "\n",
    "        pygame.draw.aalines(self.surface, color.as_int(), False, [p1, p2])\n",
    "\n",
    "    def draw_fat_segment(\n",
    "        self,\n",
    "        a: Tuple[float, float],\n",
    "        b: Tuple[float, float],\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        p1 = to_pygame(a, self.surface)\n",
    "        p2 = to_pygame(b, self.surface)\n",
    "\n",
    "        r = round(max(1, radius * 2))\n",
    "        pygame.draw.lines(self.surface, fill_color.as_int(), False, [p1, p2], r)\n",
    "        if r > 2:\n",
    "            orthog = [abs(p2[1] - p1[1]), abs(p2[0] - p1[0])]\n",
    "            if orthog[0] == 0 and orthog[1] == 0:\n",
    "                return\n",
    "            scale = radius / (orthog[0] * orthog[0] + orthog[1] * orthog[1]) ** 0.5\n",
    "            orthog[0] = round(orthog[0] * scale)\n",
    "            orthog[1] = round(orthog[1] * scale)\n",
    "            points = [\n",
    "                (p1[0] - orthog[0], p1[1] - orthog[1]),\n",
    "                (p1[0] + orthog[0], p1[1] + orthog[1]),\n",
    "                (p2[0] + orthog[0], p2[1] + orthog[1]),\n",
    "                (p2[0] - orthog[0], p2[1] - orthog[1]),\n",
    "            ]\n",
    "            pygame.draw.polygon(self.surface, fill_color.as_int(), points)\n",
    "            pygame.draw.circle(\n",
    "                self.surface,\n",
    "                fill_color.as_int(),\n",
    "                (round(p1[0]), round(p1[1])),\n",
    "                round(radius),\n",
    "            )\n",
    "            pygame.draw.circle(\n",
    "                self.surface,\n",
    "                fill_color.as_int(),\n",
    "                (round(p2[0]), round(p2[1])),\n",
    "                round(radius),\n",
    "            )\n",
    "\n",
    "    def draw_polygon(\n",
    "        self,\n",
    "        verts: Sequence[Tuple[float, float]],\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        ps = [to_pygame(v, self.surface) for v in verts]\n",
    "        ps += [ps[0]]\n",
    "\n",
    "        radius = 2\n",
    "        pygame.draw.polygon(self.surface, light_color(fill_color).as_int(), ps)\n",
    "\n",
    "        if radius > 0:\n",
    "            for i in range(len(verts)):\n",
    "                a = verts[i]\n",
    "                b = verts[(i + 1) % len(verts)]\n",
    "                self.draw_fat_segment(a, b, radius, fill_color, fill_color)\n",
    "\n",
    "    def draw_dot(\n",
    "        self, size: float, pos: Tuple[float, float], color: SpaceDebugColor\n",
    "    ) -> None:\n",
    "        p = to_pygame(pos, self.surface)\n",
    "        pygame.draw.circle(self.surface, color.as_int(), p, round(size), 0)\n",
    "\n",
    "\n",
    "def pymunk_to_shapely(body, shapes):\n",
    "    geoms = list()\n",
    "    for shape in shapes:\n",
    "        if isinstance(shape, pymunk.shapes.Poly):\n",
    "            verts = [body.local_to_world(v) for v in shape.get_vertices()]\n",
    "            verts += [verts[0]]\n",
    "            geoms.append(sg.Polygon(verts))\n",
    "        else:\n",
    "            raise RuntimeError(f'Unsupported shape type {type(shape)}')\n",
    "    geom = sg.MultiPolygon(geoms)\n",
    "    return geom\n",
    "\n",
    "# env\n",
    "class PushTEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "    reward_range = (0., 1.)\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None, damping=None,\n",
    "            render_action=True,\n",
    "            render_size=96,\n",
    "            reset_to_state=None, \n",
    "            seed=1234\n",
    "        ):\n",
    "        self._seed = seed\n",
    "        self.np_random = np.random.default_rng(seed=self._seed)\n",
    "\n",
    "        self.window_size = ws = 512  # The size of the PyGame window\n",
    "        self.render_size = render_size\n",
    "        self.sim_hz = 100\n",
    "        # Local controller params.\n",
    "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
    "        self.control_hz = self.metadata['video.frames_per_second']\n",
    "        # legcay set_state for data compatiblity\n",
    "        self.legacy = legacy\n",
    "\n",
    "        # agent_pos, block_pos, block_angle\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
    "            shape=(5,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        # positional goal for agent\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws], dtype=np.float64),\n",
    "            shape=(2,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        self.block_cog = block_cog\n",
    "        self.damping = damping\n",
    "        self.render_action = render_action\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        self.screen = None\n",
    "\n",
    "        self.space = None\n",
    "        self.teleop = None\n",
    "        self.render_buffer = None\n",
    "        self.latest_action = None\n",
    "        self.reset_to_state = reset_to_state\n",
    "\n",
    "        self._setup()\n",
    "\n",
    "    def reset(self):\n",
    "        self._setup()\n",
    "        if self.block_cog is not None:\n",
    "            self.block.center_of_gravity = self.block_cog\n",
    "        if self.damping is not None:\n",
    "            self.space.damping = self.damping\n",
    "\n",
    "        # use legacy RandomState for compatiblity\n",
    "        state = self.reset_to_state\n",
    "        if state is None:\n",
    "            \n",
    "            state = np.array([\n",
    "                self.np_random.integers(150, 350), self.np_random.integers(150, 350),\n",
    "                self.np_random.integers(150, 350), self.np_random.integers(150, 350),\n",
    "                self.np_random.uniform(-np.pi, np.pi)\n",
    "                ])\n",
    "        self._set_state(state)\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        dt = 1.0 / self.sim_hz\n",
    "        self.n_contact_points = 0\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        if action is not None:\n",
    "            self.latest_action = action\n",
    "            for i in range(n_steps):\n",
    "                # Step PD control.\n",
    "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
    "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
    "                self.agent.velocity += acceleration * dt\n",
    "\n",
    "                # Step physics.\n",
    "                self.space.step(dt)\n",
    "\n",
    "        # compute reward\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
    "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
    "\n",
    "        intersection_area = goal_geom.intersection(block_geom).area\n",
    "        goal_area = goal_geom.area\n",
    "        coverage = intersection_area / goal_area\n",
    "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
    "        done = coverage > self.success_threshold\n",
    "        terminated = done\n",
    "        truncated = done\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode):\n",
    "        return self._render_frame(mode)\n",
    "\n",
    "    def teleop_agent(self):\n",
    "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
    "        def act(obs):\n",
    "            act = None\n",
    "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
    "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
    "                self.teleop = True\n",
    "                act = mouse_position\n",
    "            return act\n",
    "        return TeleopAgent(act)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = np.array(\n",
    "            tuple(self.agent.position) \\\n",
    "            + tuple(self.block.position) \\\n",
    "            + (self.block.angle % (2 * np.pi),))\n",
    "        return obs\n",
    "\n",
    "    def _get_goal_pose_body(self, pose):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        # preserving the legacy assignment order for compatibility\n",
    "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
    "        body.position = pose[:2].tolist()\n",
    "        body.angle = pose[2]\n",
    "        return body\n",
    "\n",
    "    def _get_info(self):\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
    "        info = {\n",
    "            'pos_agent': np.array(self.agent.position),\n",
    "            'vel_agent': np.array(self.agent.velocity),\n",
    "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
    "            'goal_pose': self.goal_pose,\n",
    "            'n_contacts': n_contact_points_per_step}\n",
    "        return info\n",
    "    \n",
    "    def _get_state(self):\n",
    "        state = np.array(\n",
    "            tuple(self.agent.position) \\\n",
    "            + tuple(self.block.position) \\\n",
    "            + (self.block.angle % (2 * np.pi),))\n",
    "        return state\n",
    "\n",
    "    def _render_frame(self, mode):\n",
    "\n",
    "        if self.window is None and mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        self.screen = canvas\n",
    "\n",
    "        draw_options = DrawOptions(canvas)\n",
    "\n",
    "        # Draw goal pose.\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        for shape in self.block.shapes:\n",
    "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
    "            goal_points += [goal_points[0]]\n",
    "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
    "\n",
    "        # Draw agent and block.\n",
    "        self.space.debug_draw(draw_options)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # the clock is aleady ticked during in step for \"human\"\n",
    "\n",
    "\n",
    "        img = np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
    "        if self.render_action:\n",
    "            if self.render_action and (self.latest_action is not None):\n",
    "                action = np.array(self.latest_action)\n",
    "                coord = (action / 512 * 96).astype(np.int32)\n",
    "                marker_size = int(8/96*self.render_size)\n",
    "                thickness = int(1/96*self.render_size)\n",
    "                cv2.drawMarker(img, coord,\n",
    "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                    markerSize=marker_size, thickness=thickness)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "    def _handle_collision(self, arbiter, space, data):\n",
    "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
    "\n",
    "    def _set_state(self, state):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = state.tolist()\n",
    "        pos_agent = state[:2]\n",
    "        pos_block = state[2:4]\n",
    "        rot_block = state[4]\n",
    "        self.agent.position = pos_agent\n",
    "        # setting angle rotates with respect to center of mass\n",
    "        # therefore will modify the geometric position\n",
    "        # if not the same as CoM\n",
    "        # therefore should be modified first.\n",
    "        if self.legacy:\n",
    "            # for compatiblity with legacy data\n",
    "            self.block.position = pos_block\n",
    "            self.block.angle = rot_block\n",
    "        else:\n",
    "            self.block.angle = rot_block\n",
    "            self.block.position = pos_block\n",
    "\n",
    "        # Run physics to take effect\n",
    "        self.space.step(1.0 / self.sim_hz)\n",
    "\n",
    "    def _set_state_local(self, state_local):\n",
    "        agent_pos_local = state_local[:2]\n",
    "        block_pose_local = state_local[2:]\n",
    "        tf_img_obj = st.AffineTransform(\n",
    "            translation=self.goal_pose[:2],\n",
    "            rotation=self.goal_pose[2])\n",
    "        tf_obj_new = st.AffineTransform(\n",
    "            translation=block_pose_local[:2],\n",
    "            rotation=block_pose_local[2]\n",
    "        )\n",
    "        tf_img_new = st.AffineTransform(\n",
    "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
    "        )\n",
    "        agent_pos_new = tf_img_new(agent_pos_local)\n",
    "        new_state = np.array(\n",
    "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
    "                + [tf_img_new.rotation])\n",
    "        self._set_state(new_state)\n",
    "        return new_state\n",
    "\n",
    "    def _setup(self):\n",
    "        self.space = pymunk.Space()\n",
    "        self.space.gravity = 0, 0\n",
    "        self.space.damping = 0\n",
    "        self.teleop = False\n",
    "        self.render_buffer = list()\n",
    "\n",
    "        # Add walls.\n",
    "        walls = [\n",
    "            self._add_segment((5, 506), (5, 5), 2),\n",
    "            self._add_segment((5, 5), (506, 5), 2),\n",
    "            self._add_segment((506, 5), (506, 506), 2),\n",
    "            self._add_segment((5, 506), (506, 506), 2)\n",
    "        ]\n",
    "        self.space.add(*walls)\n",
    "\n",
    "        # Add agent, block, and goal zone.\n",
    "        self.agent = self.add_circle((256, 400), 15)\n",
    "        self.block = self.add_tee((256, 300), 0)\n",
    "        self.goal_color = pygame.Color('LightGreen')\n",
    "        self.goal_pose = np.array([256,256,np.pi/4])  # x, y, theta (in radians)\n",
    "\n",
    "        # Add collision handeling\n",
    "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
    "        self.collision_handeler.post_solve = self._handle_collision\n",
    "        self.n_contact_points = 0\n",
    "\n",
    "        self.max_score = 50 * 100\n",
    "        self.success_threshold = 0.50    # 50% coverage.\n",
    "\n",
    "    def _add_segment(self, a, b, radius):\n",
    "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
    "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
    "        return shape\n",
    "\n",
    "    def add_circle(self, position, radius):\n",
    "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
    "        body.position = position\n",
    "        body.friction = 1\n",
    "        shape = pymunk.Circle(body, radius)\n",
    "        shape.color = pygame.Color('RoyalBlue')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_box(self, position, height, width):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        body.position = position\n",
    "        shape = pymunk.Poly.create_box(body, (height, width))\n",
    "        shape.color = pygame.Color('LightSlateGray')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
    "        mass = 1\n",
    "        length = 4\n",
    "        vertices1 = [(-length*scale/2, scale),\n",
    "                                 ( length*scale/2, scale),\n",
    "                                 ( length*scale/2, 0),\n",
    "                                 (-length*scale/2, 0)]\n",
    "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        vertices2 = [(-scale/2, scale),\n",
    "                                 (-scale/2, length*scale),\n",
    "                                 ( scale/2, length*scale),\n",
    "                                 ( scale/2, scale)]\n",
    "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
    "        shape1 = pymunk.Poly(body, vertices1)\n",
    "        shape2 = pymunk.Poly(body, vertices2)\n",
    "        shape1.color = pygame.Color(color)\n",
    "        shape2.color = pygame.Color(color)\n",
    "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
    "        body.position = position\n",
    "        body.angle = angle\n",
    "        body.friction = 1\n",
    "        self.space.add(body, shape1, shape2)\n",
    "        return body\n",
    "\n",
    "class PushTImageEnv(PushTEnv):\n",
    "    metadata = {\"render.modes\": [\"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None,\n",
    "            damping=None,\n",
    "            render_size=96,\n",
    "            seed=1234):\n",
    "        super().__init__(\n",
    "            legacy=legacy,\n",
    "            block_cog=block_cog,\n",
    "            damping=damping,\n",
    "            render_size=render_size,\n",
    "            render_action=False,\n",
    "            seed=seed)\n",
    "        ws = self.window_size\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'image': spaces.Box(\n",
    "                low=0,\n",
    "                high=1,\n",
    "                shape=(3,render_size,render_size),\n",
    "                dtype=np.float32\n",
    "            ),\n",
    "            'agent_pos': spaces.Box(\n",
    "                low=0,\n",
    "                high=ws,\n",
    "                shape=(2,),\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        })\n",
    "        self.render_cache = None\n",
    "\n",
    "    def _get_obs(self):\n",
    "        img = super()._render_frame(mode='rgb_array')\n",
    "\n",
    "        agent_pos = np.array(self.agent.position)\n",
    "        img_obs = np.moveaxis(img.astype(np.float32) / 255, -1, 0)\n",
    "        obs = {\n",
    "            'image': img_obs,\n",
    "            'agent_pos': agent_pos\n",
    "        }\n",
    "\n",
    "        # draw action\n",
    "        if self.latest_action is not None:\n",
    "            action = np.array(self.latest_action)\n",
    "            coord = (action / 512 * 96).astype(np.int32)\n",
    "            marker_size = int(8/96*self.render_size)\n",
    "            thickness = int(1/96*self.render_size)\n",
    "            cv2.drawMarker(img, coord,\n",
    "                color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                markerSize=marker_size, thickness=thickness)\n",
    "        self.render_cache = img\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def render(self, mode):\n",
    "        assert mode == 'rgb_array'\n",
    "\n",
    "        if self.render_cache is None:\n",
    "            self._get_obs()\n",
    "\n",
    "        return self.render_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pusht_data_stats.pkl', 'rb') as f:\n",
    "    state_data_stats = pickle.load(f)\n",
    "\n",
    "with open('./vision_data_stats.pkl', 'rb') as f:\n",
    "    vision_data_stats = pickle.load(f)\n",
    "\n",
    "def normalize_data(data, stats):\n",
    "    # nomalize to [0,1]\n",
    "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
    "    # normalize to [-1, 1]\n",
    "    ndata = ndata * 2 - 1\n",
    "    return ndata\n",
    "\n",
    "def unnormalize_data(ndata, stats):\n",
    "    ndata = (ndata + 1) / 2\n",
    "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 8.414285e+07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# immstate = ImmState(\n",
    "#     sigma_data=state_data_stats['action_normalized']['std'].mean(),\n",
    "#     obs_horizon=2,\n",
    "#     pred_horizon=16,\n",
    "#     num_particles=4,\n",
    "#     seed=12345\n",
    "# )\n",
    "# immstate.load_model('imm/ckpts/state.pth')\n",
    "\n",
    "immvision = ImmVision(\n",
    "    sigma_data=vision_data_stats['action_normalized']['std'].mean(),\n",
    "    obs_horizon=2,\n",
    "    pred_horizon=16,\n",
    "    num_particles=4,\n",
    "    seed=12345\n",
    ")\n",
    "immvision.load_model('imm/ckpts/model_checkpoint_15_0_0.039065733551979065.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model, diffusion_steps=1, mode='state'):\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    time_mult = 10.0\n",
    "\n",
    "    # limit enviornment interaction to 350 steps before termination\n",
    "    max_steps = 1000\n",
    "    if mode == 'state':\n",
    "        env = PushTEnv(seed=12345)\n",
    "    elif mode == 'vision':\n",
    "        env = PushTImageEnv(seed=12345)\n",
    "\n",
    "    render = False\n",
    "    env_timestep = 1.0 / env.sim_hz\n",
    "\n",
    "\n",
    "    episodes = 10\n",
    "    # starts = np.zeros((episodes, 5))\n",
    "    # ends = np.zeros((episodes, 5))\n",
    "    steps = np.zeros(episodes)\n",
    "    avgtimes = np.zeros(episodes)\n",
    "    idle_steps = np.zeros(episodes)\n",
    "\n",
    "    # save rewards\n",
    "    final_rewards = np.zeros(episodes)\n",
    "\n",
    "    with tqdm(total=episodes, desc=\"Eval PushTStateEnv\") as pbar:\n",
    "        for ep in range(episodes):\n",
    "            reward = 0.0\n",
    "\n",
    "            # reset model\n",
    "            model.reset()\n",
    "            \n",
    "            # get first observation\n",
    "            obs, info = env.reset()\n",
    "            if render:\n",
    "                imgs = [env.render(mode='rgb_array')]\n",
    "            # starts[ep] = env._get_state()\n",
    "            \n",
    "            # keep a queue of last 2 steps of observations\n",
    "            obs_deque = collections.deque([obs] * model.obs_horizon, maxlen=model.obs_horizon)\n",
    "\n",
    "            done = False\n",
    "            step_idx = 0\n",
    "            eptimes = []\n",
    "            last_action = []\n",
    "\n",
    "            # stats\n",
    "            total_step_lens = []\n",
    "            inference_times = []\n",
    "            idle = 0.0\n",
    "        \n",
    "            while not done:\n",
    "                if mode == 'state':\n",
    "                    # stack the last obs_horizon (2) number of observations\n",
    "                    obs_seq = np.stack(obs_deque)\n",
    "                    # normalize observation\n",
    "                    nobs = normalize_data(obs_seq, stats=state_data_stats['obs'])\n",
    "                    # device transfer\n",
    "                    nobs = torch.from_numpy(nobs).unsqueeze(0).flatten(start_dim=1).to(device, dtype=torch.float32)\n",
    "                elif mode == 'vision':\n",
    "                    images = np.stack([x['image'] for x in obs_deque])\n",
    "                    images = torch.from_numpy(images).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "                    agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
    "                    nagent_poses = normalize_data(agent_poses, stats=vision_data_stats['agent_pos'])\n",
    "                    nagent_poses = torch.from_numpy(nagent_poses).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "    \n",
    "\n",
    "                # infer action\n",
    "                with torch.no_grad():\n",
    "                    start_time = time.monotonic()\n",
    "                    if mode == 'state':\n",
    "                        r = model.sample(shape=(1, model.pred_horizon, model.action_dim), steps=diffusion_steps, global_cond=nobs)\n",
    "                    elif mode == 'vision':\n",
    "                        r = model.sample(shape=(1, model.pred_horizon, model.action_dim), image=images, agent_pos=nagent_poses, steps=diffusion_steps)\n",
    "                    end_time = time.monotonic()\n",
    "                inference_time = end_time - start_time\n",
    "                inference_times.append(inference_time)\n",
    "                eptimes.append(1000 * inference_time)\n",
    "\n",
    "                # unnormalize action\n",
    "                naction = r.detach().to('cpu').numpy()\n",
    "                # (B, pred_horizon, action_dim)\n",
    "                naction = naction[0]\n",
    "                if mode == 'state':\n",
    "                    action_pred = unnormalize_data(naction, stats=state_data_stats['action'])\n",
    "                elif mode == 'vision':\n",
    "                    action_pred = unnormalize_data(naction, stats=vision_data_stats['action'])\n",
    "\n",
    "                # execute action_horizon number of steps from the last action\n",
    "                # without replanning\n",
    "                for i in range(len(last_action)):\n",
    "                    # stepping env\n",
    "                    obs, reward, done, _, info = env.step(last_action[i])\n",
    "                    # save observations\n",
    "                    obs_deque.append(obs)\n",
    "                    if render:\n",
    "                        imgs.append(env.render(mode='rgb_array'))\n",
    "\n",
    "                    step_idx += 1\n",
    "                    if step_idx > max_steps:\n",
    "                        done = True\n",
    "                    if done:\n",
    "                        break\n",
    "\n",
    "                # compute the number of steps to execute, stall for all steps above the action horizon\n",
    "                inference_time *= time_mult\n",
    "                total_steps = int(np.ceil(inference_time / env_timestep))\n",
    "                action_steps = min(total_steps, model.pred_horizon - model.obs_horizon + 1)\n",
    "                last_action = np.zeros((total_steps, model.action_dim))\n",
    "                start = model.obs_horizon - 1\n",
    "                end = start + action_steps\n",
    "                last_action[:action_steps,:] = action_pred[start:end,:]\n",
    "                last_action[action_steps:,:] = last_action[action_steps-1,:]\n",
    "                \n",
    "                total_step_lens.append(total_steps)\n",
    "                idle += total_steps - action_steps\n",
    "            # print(np.mean(total_step_lens), np.mean(inference_times))\n",
    "\n",
    "            # ends[ep] = env._get_state()\n",
    "            steps[ep] = step_idx\n",
    "            avgtimes[ep] = np.mean(eptimes)\n",
    "            idle_steps[ep] = idle\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(avg_reward=sum(final_rewards[:ep+1])/(ep+1), total_steps=steps[:ep+1].mean(), idle_steps=idle_steps[:ep+1].mean())\n",
    "            final_rewards[ep] = reward\n",
    "    print(f'Final reward: {sum(final_rewards)/episodes}')\n",
    "    return final_rewards, idle_steps, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1 = benchmark(immstate, 1)\n",
    "# b2 = benchmark(immstate, 2)\n",
    "# b4 = benchmark(immstate, 4)\n",
    "# b8 = benchmark(immstate, 8)\n",
    "# b16 = benchmark(immstate, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:20<00:00,  2.01s/it, avg_reward=0.3, idle_steps=0, total_steps=839]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:13<00:00,  1.33s/it, avg_reward=0.6, idle_steps=0, total_steps=577]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:13<00:00,  1.37s/it, avg_reward=0.5, idle_steps=0, total_steps=572]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:15<00:00,  1.50s/it, avg_reward=0.554, idle_steps=176, total_steps=621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6535068087123163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:18<00:00,  1.88s/it, avg_reward=0.473, idle_steps=508, total_steps=764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.4728475321753038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:20<00:00,  2.06s/it, avg_reward=0.447, idle_steps=758, total_steps=801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.5010032650933154\n",
      "40 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:20<00:00,  2.08s/it, avg_reward=0.211, idle_steps=0, total_steps=875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.21082369182699354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it, avg_reward=0.672, idle_steps=0, total_steps=506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.7720695462263156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it, avg_reward=0.6, idle_steps=0, total_steps=480]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it, avg_reward=0.6, idle_steps=173, total_steps=587]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:18<00:00,  1.89s/it, avg_reward=0.543, idle_steps=512, total_steps=764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.5428792659069493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, avg_reward=0.416, idle_steps=839, total_steps=894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.4160948322997437\n",
      "60 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:19<00:00,  1.93s/it, avg_reward=0.3, idle_steps=0, total_steps=809]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:13<00:00,  1.33s/it, avg_reward=0.5, idle_steps=0, total_steps=573]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:16<00:00,  1.68s/it, avg_reward=0.432, idle_steps=0, total_steps=691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.5317918609974026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it, avg_reward=0.6, idle_steps=134, total_steps=447]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it, avg_reward=0.509, idle_steps=413, total_steps=603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6091681767918578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:22<00:00,  2.21s/it, avg_reward=0.377, idle_steps=805, total_steps=856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.4773558956465149\n",
      "80 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it, avg_reward=0.6, idle_steps=0, total_steps=526]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it, avg_reward=0.7, idle_steps=0, total_steps=463]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:08<00:00,  1.13it/s, avg_reward=0.7, idle_steps=0, total_steps=359]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it, avg_reward=0.741, idle_steps=150, total_steps=496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.7407014352129604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it, avg_reward=0.651, idle_steps=388, total_steps=566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.651139337574196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:19<00:00,  1.91s/it, avg_reward=0.685, idle_steps=708, total_steps=734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.713616834794401\n",
      "100 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:14<00:00,  1.48s/it, avg_reward=0.5, idle_steps=0, total_steps=614]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.5362761912877657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:07<00:00,  1.32it/s, avg_reward=0.8, idle_steps=0, total_steps=324]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it, avg_reward=0.757, idle_steps=0, total_steps=414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.8572030210537814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:13<00:00,  1.31s/it, avg_reward=0.6, idle_steps=160, total_steps=539]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:14<00:00,  1.50s/it, avg_reward=0.531, idle_steps=409, total_steps=603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.6311546187280772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval PushTStateEnv: 100%|██████████| 10/10 [00:20<00:00,  2.00s/it, avg_reward=0.462, idle_steps=735, total_steps=772]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reward: 0.5110981932044758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('20 epochs')\n",
    "immvision.load_model('imm/ckpts/model_checkpoint_15_0_0.039065733551979065.pth')\n",
    "bv1_20 = benchmark(immvision, 1, mode='vision')\n",
    "bv2_20 = benchmark(immvision, 2, mode='vision')\n",
    "bv4_20 = benchmark(immvision, 4, mode='vision')\n",
    "bv8_20 = benchmark(immvision, 8, mode='vision')\n",
    "bv16_20 = benchmark(immvision, 16, mode='vision')\n",
    "bv32_20 = benchmark(immvision, 32, mode='vision')\n",
    "print('40 epochs')\n",
    "immvision.load_model('imm/ckpts/vision_30.pth')\n",
    "bv1_40 = benchmark(immvision, 1, mode='vision')\n",
    "bv2_40 = benchmark(immvision, 2, mode='vision')\n",
    "bv4_40 = benchmark(immvision, 4, mode='vision')\n",
    "bv8_40 = benchmark(immvision, 8, mode='vision')\n",
    "bv16_40 = benchmark(immvision, 16, mode='vision')\n",
    "bv32_40 = benchmark(immvision, 32, mode='vision')\n",
    "print('60 epochs')\n",
    "immvision.load_model('imm/ckpts/vision_45.pth')\n",
    "bv1_60 = benchmark(immvision, 1, mode='vision')\n",
    "bv2_60 = benchmark(immvision, 2, mode='vision')\n",
    "bv4_60 = benchmark(immvision, 4, mode='vision')\n",
    "bv8_60 = benchmark(immvision, 8, mode='vision')\n",
    "bv16_60 = benchmark(immvision, 16, mode='vision')\n",
    "bv32_60 = benchmark(immvision, 32, mode='vision')\n",
    "print('80 epochs')\n",
    "immvision.load_model('imm/ckpts/vision_60.pth')\n",
    "bv1_80 = benchmark(immvision, 1, mode='vision')\n",
    "bv2_80 = benchmark(immvision, 2, mode='vision')\n",
    "bv4_80 = benchmark(immvision, 4, mode='vision')\n",
    "bv8_80 = benchmark(immvision, 8, mode='vision')\n",
    "bv16_80 = benchmark(immvision, 16, mode='vision')\n",
    "bv32_80 = benchmark(immvision, 32, mode='vision')\n",
    "print('100 epochs')\n",
    "immvision.load_model('imm/ckpts/vision_75.pth')\n",
    "bv1_100 = benchmark(immvision, 1, mode='vision')\n",
    "bv2_100 = benchmark(immvision, 2, mode='vision')\n",
    "bv4_100 = benchmark(immvision, 4, mode='vision')\n",
    "bv8_100 = benchmark(immvision, 8, mode='vision')\n",
    "bv16_100 = benchmark(immvision, 16, mode='vision')\n",
    "bv32_100 = benchmark(immvision, 32, mode='vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
